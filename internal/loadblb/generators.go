// Copyright (c) 2016 Western Digital Corporation or its affiliates. All rights reserved.
// SPDX-License-Identifier: MIT

package loadblb

import (
	"math"
	"math/rand"
	"sync"

	log "github.com/golang/glog"
	"github.com/westerndigitalcorporation/blb/client/blb"
)

// Generators are defined here. A generator is a vertex in the graph that is
// used to generate test workload against a blb cluster (see "graph.go"). Each
// generator is initialized with a unique name, start and end times, and two
// variates that represent event arrival rate and I/O byte size, respectively.
//
// Generators are categorized into WriteGenerators and ReadGenerators
// (abbreviated as Writers and Readers below if no further confusions).
//
// A writer is further initalized with a set of readers (those vertices
// connected with itself in the graph) and variate for replication factor. Only
// these readers can read the blobs created by this writer. A writer generates
// write events, each of which defines an event involving creating a blob with a
// given replication factor and size. Write events are tagged with the set of
// readers connected to their writers so that the created blobs are inserted
// into the "collections" associated with the readers (see below).
//
// A reader is further initialized with a blob collection and a recentN
// parameter. Each read event specifies the operation of reading a given size of
// bytes from a blob. The blob is picked uniformly at random from the 'recentN'
// most recently created blobs in the blob collection. Read events are tagged
// with the name of the readers that generate them so that they can be correctly
// associated with the proper blob collections.
//
// It should be clear from the description above that we follow a "push" model
// here: writers push their results (blobs) into readers' buffers (blob
// collections). If a writer is connected with multiple readers, each of the
// reader will obtain a copy of the blob references created by the writer.
//
// Generators only generate events that define the expected operations. The
// actual execution of such operations (i.e., interacting with the blb cluster
// to do actual I/Os) is perfomed by a separate load handler (see "graph.go" and
// "handler.go").

type writeEvent struct {
	readers    []string // The names of the readers that can read the blob written in this event.
	size       int64    // The byte size of the write.
	replFactor int      // Replication factor.
}

// An event generated by a reader.
type readEvent struct {
	reader string // The name of the reader that generates this event.
	size   int64  // The byte size of the read.

	// Only most recent blobs can be read. recent<=0 means all blobs.

	// Most of the read traffic has correlation with writes, i.e., the most
	// recently written blobs tend to be popular for reads. To capture this,
	// one can specify this value to mean that read events only target at
	// the most recent 'recentN' blobs that the reader can read.  If
	// recentN<=0, read events will target all blobs that this reader can
	// read.
	recentN int
}

// Generator defines load generator to be implemented by WriteGenerator and
// ReadGenerator.
type Generator interface {
	// Generate write/read events when the generate is active, nil otherwise.
	Gen() []interface{}
}

// baseGenerator is the base implementation for Generator. Both WriteGenerator
// and ReadGenerator encapsulate baseGenerator.
type baseGenerator struct {
	// Name of this generator.
	name string

	// When to activate and deactive the generator?
	// ... and a counter to represent the current time. Incremented by one
	// each time when 'Gen' is called.
	start int64
	end   int64
	now   int64

	// Event arrival rate and I/O byte size.
	rate Variate
	size Variate
}

func newBaseGenerator(cfg generatorConfig) *baseGenerator {
	if cfg.Start < 0 || cfg.End < 0 || cfg.Start >= cfg.End {
		log.Fatalf("invalid parameters: start %d, end %d", cfg.Start, cfg.End)
	}
	return &baseGenerator{
		name:  cfg.Name,
		start: cfg.Start,
		end:   cfg.End,
		now:   -1, // The first thing we do in genSizes() is to increment now so make it starts at -1.
		rate:  cfg.Rate.Parse(),
		size:  cfg.Size.Parse(),
	}
}

// Generate event byte sizes to be used by the generators that encapsulate it.
func (g *baseGenerator) genSizes() []int64 {
	g.now++
	if g.now < g.start || g.now >= g.end {
		return nil
	}

	// How many events arrive during this interval?
	numEvents := int64(g.rate.Sample())
	if numEvents <= 0 {
		return nil
	}

	ret := make([]int64, numEvents)
	for i := range ret {
		// While the random sample can be negative, byte size cannot be.
		// So make it non-negative.
		ret[i] = maxInt64(0, int64(g.size.Sample()))
	}
	return ret
}

// WriteGenerator generates write events.
type WriteGenerator struct {
	*baseGenerator

	// The names of the readers that can read the blobs generated by this
	// writer. These blobs will be inserted into the blobCollections
	// associated with the readers.
	readers []string

	// Replication factor. Samples will be rounded and lower bounded by 1.
	replFactor Variate
}

// NewWriteGenerator createsa a new WriteGenerator.
func NewWriteGenerator(cfg WriteGenConfig) *WriteGenerator {
	return &WriteGenerator{
		baseGenerator: newBaseGenerator(cfg.generatorConfig),
		readers:       cfg.Readers,
		replFactor:    cfg.ReplFactor.Parse(),
	}
}

// Gen implements Generator.
func (w *WriteGenerator) Gen() []interface{} {
	sizes := w.genSizes()
	if sizes == nil {
		return nil
	}

	writes := make([]interface{}, len(sizes))
	for i, s := range sizes {
		writes[i] = writeEvent{
			readers: w.readers,
			size:    s,
			// Replication factor should be an int >=1.
			replFactor: int(math.Max(w.replFactor.Sample(), 1)),
		}
	}
	log.Infof("%d new write events arrived", len(writes))
	return writes
}

// ReadGenerator generates read events.
type ReadGenerator struct {
	*baseGenerator

	// The set of blobs we can generate reads from.
	col *blobCollection

	// Most of the read traffic has correlation with writes, i.e., the most
	// recently written blobs tend to be popular for reads. To capture this,
	// one can specify this value to mean that read events only target at
	// the most recent 'recentN' blobs that the reader can read.  If
	// recentN<=0, read events will target all blobs that this reader can
	// read.
	recentN int
}

// NewReadGenerator createsa a new ReadGenerator.
func NewReadGenerator(cfg ReadGenConfig) *ReadGenerator {
	return &ReadGenerator{
		baseGenerator: newBaseGenerator(cfg.generatorConfig),
		col:           newBlobCollection(),
		recentN:       cfg.RecentN,
	}
}

// Gen implements Generator.
func (r *ReadGenerator) Gen() []interface{} {
	sizes := r.genSizes()
	if sizes == nil {
		return nil
	}

	reads := make([]interface{}, len(sizes))
	for i, s := range sizes {
		reads[i] = readEvent{
			reader:  r.name,
			size:    s,
			recentN: r.recentN,
		}
	}
	log.Infof("%d new read events arrived", len(reads))
	return reads
}

//======= blobCollection ======//

type blobInfo struct {
	id   blb.BlobID
	size int64
}

// blobCollection represents a collection of blobs and facilitates retrieving
// random blobs from the collections.
type blobCollection struct {
	lock  sync.Mutex          // Lock for everything below.
	blobs []blobInfo          // Sorted in the insertion order.
	seen  map[blb.BlobID]bool // Don't allow duplicate blobs.
}

// newBlobCollection creates a new BlobCollection. We are going to populate a
// collection with "writers" and then "readers" can retrieve blobs from it.
func newBlobCollection() *blobCollection {
	return &blobCollection{seen: make(map[blb.BlobID]bool)}
}

// Put a blob into the colllection.
func (c *blobCollection) put(id blb.BlobID, size int64) {
	c.lock.Lock()
	defer c.lock.Unlock()

	if c.seen[id] {
		log.Fatalf("blob %s already exists", id)
	}
	c.blobs = append(c.blobs, blobInfo{id: id, size: size})
	c.seen[id] = true
}

// Retrieve a random blob from the most recent 'n' blobs in the collection. If
// 'n' is non-positive or exceeds the length of the collection, treat 'n' as
// equal to the length. If the colleciton is empty, 'ok' is flagged as false.
func (c *blobCollection) getRandRecent(n int) (id blb.BlobID, size int64, ok bool) {
	c.lock.Lock()
	defer c.lock.Unlock()

	// Return false if it's empty.
	length := len(c.blobs)
	if length == 0 {
		return 0, 0, false
	}

	// Check n.
	if n <= 0 || n > length {
		n = length
	}

	// Get a random blob from the last n inserted into the collection.
	b := c.blobs[length-n+rand.Intn(n)]
	return b.id, b.size, true
}
