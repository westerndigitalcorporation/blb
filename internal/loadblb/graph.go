// Copyright (c) 2016 Western Digital Corporation or its affiliates. All rights reserved.
// SPDX-License-Identifier: MIT

package loadblb

import (
	"fmt"
	"time"

	log "github.com/golang/glog"

	client "github.com/westerndigitalcorporation/blb/client/blb"
)

// A Graph (a bipartite graph really) represents a traffic scenario. The graph
// consists of a set of writers and a set of readers. If there is an edge
// between a writer and reader, the reader can generate load to access blobs
// written by the writer. There is no restriction on the vertex degrees -- a
// writer can connect to multiple readers and vice versa.
//
// Internally, each reader is associated with a blobCollection. If a writer is
// connected to a reader, blobs generated by the writer will be inserted into
// the reader's blobCollection. In other words, the graph follows a "push" model
// where writers push their results into readers' buffers.
//
// Each vertex has its own starting and ending time, between which the genertor
// is activated. When it is activated, on each clock tick (of the graph), it
// generates events according to its configured behavior. A generator stops
// generating events after it passes the end time; however, previously generated
// events of this generator can still cause I/O operations after that point.
//
// While it totally makes sense to have zero readers, it is not to have zero
// writers as readers won't have any blobs to access.
//
// The graph also has a load handler, which accepts the generated events and
// execute the I/O operations against a blb cluster.
//
// NOTE: We don't mutate these fields so no lock is required on Graph.
type Graph struct {
	// Configurations for load generators.
	writers []*WriteGenerator
	readers []*ReadGenerator

	// Mapping from readers to their associated blob collections.
	collections map[string]*blobCollection

	// Load handler.
	handler *LoadHandler

	// How often do we tick? All generators's Gen() method will be invoked
	// at each tick.
	tickInterval time.Duration

	// When shall we stop if no early errors?

	// Once 'Run' method is invoked, it stops whenever an error is
	// encountered or when all generators stop generating events. This is
	// set to the largest end time of all generators in the graph.
	end int64

	// Whether cleanup blobs that were created after the load testing is done.
	cleanupWhenDone bool
}

// NewGraph creates a new Graph.
func NewGraph(cfg GraphConfig) *Graph {
	// We parse the configuration in the constructor so that the caller
	// doesn't need to do so.
	cfg.parseDuration()

	if len(cfg.Writers) == 0 {
		log.Fatalf("no writers configured")
	}

	// The end time of the graph should be the last moment when all
	// generators stop, if no early errors.
	var end int64
	// Generators should have distinct names.
	seen := make(map[string]bool)

	writers := make([]*WriteGenerator, 0, len(cfg.Writers))
	readers := make([]*ReadGenerator, 0, len(cfg.Readers))
	collections := make(map[string]*blobCollection, len(readers))

	// Create writers.
	for _, w := range cfg.Writers {
		if seen[w.Name] {
			log.Fatalf("duplicate generator name: %s", w.Name)
		}
		seen[w.Name] = true
		writers = append(writers, NewWriteGenerator(w))
		if end < w.End {
			end = w.End
		}
	}

	// Create readers.
	for _, r := range cfg.Readers {
		if seen[r.Name] {
			log.Fatalf("duplicate generator name: %s", r.Name)
		}
		seen[r.Name] = true
		reader := NewReadGenerator(r)
		readers = append(readers, reader)
		collections[r.Name] = reader.col
		if end < r.End {
			end = r.End
		}
	}

	// Create a load handler.
	handler := NewLoadHandler(cfg.Handler)

	return &Graph{
		writers:         writers,
		readers:         readers,
		collections:     collections,
		handler:         handler,
		tickInterval:    cfg.tickInterval,
		end:             end,
		cleanupWhenDone: cfg.CleanupWhenDone,
	}
}

// Run executes the traffic scenario defined by the graph. Stats and error, if
// any, are returned.
func (g *Graph) Run() (string, error) {
	defer g.cleanup()

	ticker := time.NewTicker(g.tickInterval)
	g.handler.Start(g.collections)
	var ret handlerResult

	log.Infof("start generating load...")
	ticks := g.end
	for ticks > 0 {
		<-ticker.C

		// Generate events.
		for _, w := range g.writers {
			g.handler.Accept(w.Gen())
		}
		for _, r := range g.readers {
			g.handler.Accept(r.Gen())
		}
		ticks--

		// Check I/O errors.
		select {
		case ret = <-g.handler.DoneC:
			return ret.stats, ret.err
		default:
		}
	}
	ticker.Stop()
	g.handler.Stop()

	ret = <-g.handler.DoneC
	return ret.stats, ret.err
}

// Remove all the generated blobs.
func (g *Graph) cleanup() {
	if g.cleanupWhenDone {
		log.Infof("removing all generated blobs...")
		g.handler.Cleanup()
	}
}

// FixedWriteRead is an example scenario to faciliate simple load tests.
// There is a single writer and a single reader, generating fixed number of
// fixed-size events in each interval (1 second). The writer is active in the
// first 1/4 of the run, while the reader is active for the rest of the time.
//
// An example JSON configuration is shown below, assuming cluster="m0,m1,m2",
// duration=200s, rate=2000, and size=8MB.
/*
{
	"Writers": [{
		"Name": "writer",
		"Start": 0,
		"End": 100,
		"Rate": {
			"Name": "Constant",
			"Parameters": 2000
		},
		"Size": {
			"Name": "Constant",
			"Parameters": 8388608
		},
		"Readers": ["reader"],
		"ReplFactor": {
			"Name": "Constant",
			"Parameters": 3
		}
	}],

	"Readers": [{
		"Name": "reader",
		"Start": 100,
		"End": 200,
		"Rate": {
			"Name": "Constant",
			"Parameters": 2000
		},
		"Size": {
			"Name": "Constant",
			"Parameters": 8388608
		},
		"RecentN": 0
	}],

	"Handler":{
		"Cluster": "m0,m1,m2",
		"RetryTimeout": "3m",
		"NumWorkers": 5,
		"QueueLength": 20000
	},

	"TickInterval": "1s"
}
*/
func FixedWriteRead(cluster string, duration time.Duration, rate, size int64, repl int) (string, error) {
	// Compute total ticks.
	ticks := duration.Nanoseconds() / time.Second.Nanoseconds()

	// Create constant distributions.
	if rate < 0 || size < 0 || repl < 0 {
		return "", fmt.Errorf("rate, size, and repl cannot be negative")
	}
	rateV := VariateConfig{Name: "Constant", Parameters: []byte(fmt.Sprintf("%d", rate))}
	sizeV := VariateConfig{Name: "Constant", Parameters: []byte(fmt.Sprintf("%d", size))}
	replV := VariateConfig{Name: "Constant", Parameters: []byte(fmt.Sprintf("%d", repl))}

	// Create a single writer,
	writer := WriteGenConfig{
		generatorConfig: generatorConfig{
			Name:  "writer",
			Start: 0,
			End:   ticks / 4,
			Rate:  rateV,
			Size:  sizeV,
		},
		Readers:    []string{"reader"},
		ReplFactor: replV,
	}
	// ... a single reader,
	reader := ReadGenConfig{
		generatorConfig: generatorConfig{
			Name:  "reader",
			Start: ticks / 4,
			End:   ticks,
			Rate:  rateV,
			Size:  sizeV,
		},
		RecentN: 0,
	}
	// ... and a handler.
	handler := HandlerConfig{
		Options:      client.Options{Cluster: cluster, RetryTimeout: 3 * time.Minute},
		RetryTimeout: "3m",
		NumWorkers:   5,
		QueueLength:  20000,
	}

	// Make the graph.
	graph := GraphConfig{
		Writers:         []WriteGenConfig{writer},
		Readers:         []ReadGenConfig{reader},
		Handler:         handler,
		TickInterval:    "1s",
		CleanupWhenDone: true,
	}

	// Run it.
	return NewGraph(graph).Run()
}
